{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "3b97f6205e13cf85ea01e4081d87b6f06bf272a6e460f325999b991fb6c68282"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_reader(fname):\n",
    "    \"\"\"\n",
    "        Read multiple json files\n",
    "        Args:\n",
    "            fname: str: input file\n",
    "        Returns:\n",
    "            generator: iterator over documents \n",
    "    \"\"\"\n",
    "    for line in open(fname, mode=\"r\"):\n",
    "        yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = \"C:/IITD/sem5/col774-ml/datasets/col774_yelp_data/col774_yelp_data/train.json\"\n",
    "test_json = \"C:/IITD/sem5/col774-ml/datasets/col774_yelp_data/col774_yelp_data/test.json\"\n",
    "\n",
    "y = []\n",
    "docs = []\n",
    "\n",
    "for review in json_reader(train_json):\n",
    "    y.append(int(review[\"stars\"]))\n",
    "    docs.append(review[\"text\"])\n",
    "\n",
    "y_train = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "docs_test = []\n",
    "\n",
    "for review in json_reader(test_json):\n",
    "    y_test.append(int(review[\"stars\"]))\n",
    "    docs_test.append(review[\"text\"])\n",
    "\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# naive bayes\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf.fit(docs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.46974229348330065"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6697527632779431"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "predicted = svm_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(verbose=10)),\n",
    "])\n",
    "\n",
    "sgd_clf.fit(docs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6332580505242376"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "predicted = sgd_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[18123,   216,   314,   152,  1364],\n",
       "       [ 5865,   727,  1738,   983,  1525],\n",
       "       [ 2655,   419,  3078,  4393,  3986],\n",
       "       [ 1073,   118,  1002,  6268, 20897],\n",
       "       [  773,    39,   194,  1334, 56482]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "-- Epoch 1\n",
      "Norm: 51.11, NNZs: 152236, Bias: -1.088210, T: 10000, Avg. loss: 0.221475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.98, NNZs: 186141, Bias: -0.819930, T: 20000, Avg. loss: 0.105143\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44.42, NNZs: 199504, Bias: -0.777342, T: 30000, Avg. loss: 0.082523\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44.21, NNZs: 208083, Bias: -0.731726, T: 40000, Avg. loss: 0.072955\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 43.93, NNZs: 212479, Bias: -0.706129, T: 50000, Avg. loss: 0.065632\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 43.66, NNZs: 215714, Bias: -0.704410, T: 60000, Avg. loss: 0.061367\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 43.63, NNZs: 217816, Bias: -0.702810, T: 70000, Avg. loss: 0.058718\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43.61, NNZs: 219511, Bias: -0.683058, T: 80000, Avg. loss: 0.056105\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 43.57, NNZs: 220656, Bias: -0.691642, T: 90000, Avg. loss: 0.054276\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.60, NNZs: 221857, Bias: -0.673763, T: 100000, Avg. loss: 0.053022\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 43.61, NNZs: 222613, Bias: -0.670578, T: 110000, Avg. loss: 0.051695\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 43.56, NNZs: 223024, Bias: -0.667521, T: 120000, Avg. loss: 0.050717\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.55, NNZs: 223464, Bias: -0.662674, T: 130000, Avg. loss: 0.050160\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43.53, NNZs: 224537, Bias: -0.659416, T: 140000, Avg. loss: 0.049346\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.57, NNZs: 224841, Bias: -0.664385, T: 150000, Avg. loss: 0.048772\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.58, NNZs: 225017, Bias: -0.662483, T: 160000, Avg. loss: 0.048047\n",
      "Total training time: 0.19 seconds.\n",
      "Convergence after 16 epochs took 0.19 seconds\n",
      "-- Epoch 1\n",
      "Norm: 34.26, NNZs: 111381, Bias: -1.255412, T: 10000, Avg. loss: 0.196177\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.14, NNZs: 149585, Bias: -1.147670, T: 20000, Avg. loss: 0.128482\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.45, NNZs: 179775, Bias: -1.085409, T: 30000, Avg. loss: 0.108489\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.22, NNZs: 198306, Bias: -1.075040, T: 40000, Avg. loss: 0.099435\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.14, NNZs: 210931, Bias: -1.047191, T: 50000, Avg. loss: 0.094282\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.11, NNZs: 219119, Bias: -1.031312, T: 60000, Avg. loss: 0.091014\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 30.10, NNZs: 225084, Bias: -1.013783, T: 70000, Avg. loss: 0.088595\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 30.11, NNZs: 230917, Bias: -1.008464, T: 80000, Avg. loss: 0.086480\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 30.12, NNZs: 235080, Bias: -1.009619, T: 90000, Avg. loss: 0.085129\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 30.13, NNZs: 238331, Bias: -0.993352, T: 100000, Avg. loss: 0.084155\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 30.13, NNZs: 240537, Bias: -0.994072, T: 110000, Avg. loss: 0.083219\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 30.14, NNZs: 242669, Bias: -0.986862, T: 120000, Avg. loss: 0.082335\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 30.15, NNZs: 244735, Bias: -0.987549, T: 130000, Avg. loss: 0.081880\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 30.16, NNZs: 246725, Bias: -0.977148, T: 140000, Avg. loss: 0.081448\n",
      "Total training time: 0.17 seconds.\n",
      "Convergence after 14 epochs took 0.17 seconds\n",
      "-- Epoch 1\n",
      "Norm: 40.19, NNZs: 135467, Bias: -1.269526, T: 10000, Avg. loss: 0.261029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.84, NNZs: 179893, Bias: -1.117949, T: 20000, Avg. loss: 0.168463\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.14, NNZs: 207497, Bias: -1.077437, T: 30000, Avg. loss: 0.140845\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35.94, NNZs: 224712, Bias: -1.040844, T: 40000, Avg. loss: 0.128629\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35.86, NNZs: 234277, Bias: -1.017036, T: 50000, Avg. loss: 0.121541\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.86, NNZs: 241500, Bias: -0.993725, T: 60000, Avg. loss: 0.116818\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 35.87, NNZs: 246622, Bias: -0.987171, T: 70000, Avg. loss: 0.113546\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 35.88, NNZs: 250030, Bias: -0.986505, T: 80000, Avg. loss: 0.110788\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 35.91, NNZs: 252729, Bias: -0.969918, T: 90000, Avg. loss: 0.108966\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 35.91, NNZs: 255137, Bias: -0.956915, T: 100000, Avg. loss: 0.107703\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 35.93, NNZs: 256825, Bias: -0.954551, T: 110000, Avg. loss: 0.106071\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 35.95, NNZs: 257925, Bias: -0.959097, T: 120000, Avg. loss: 0.105422\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 35.96, NNZs: 259062, Bias: -0.947480, T: 130000, Avg. loss: 0.104389\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 35.97, NNZs: 260146, Bias: -0.939964, T: 140000, Avg. loss: 0.103595\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 35.97, NNZs: 261623, Bias: -0.941982, T: 150000, Avg. loss: 0.103132\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 35.98, NNZs: 262072, Bias: -0.938541, T: 160000, Avg. loss: 0.102484\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 35.99, NNZs: 262620, Bias: -0.933045, T: 170000, Avg. loss: 0.102009\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 36.00, NNZs: 263323, Bias: -0.940194, T: 180000, Avg. loss: 0.101584\n",
      "Total training time: 0.22 seconds.\n",
      "Convergence after 18 epochs took 0.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 55.42, NNZs: 198048, Bias: -1.221191, T: 10000, Avg. loss: 0.499992\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 52.64, NNZs: 248373, Bias: -1.053334, T: 20000, Avg. loss: 0.293695\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 52.21, NNZs: 267356, Bias: -1.019425, T: 30000, Avg. loss: 0.240966\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 52.15, NNZs: 276128, Bias: -0.936504, T: 40000, Avg. loss: 0.216799\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 52.19, NNZs: 280797, Bias: -0.916285, T: 50000, Avg. loss: 0.202963\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 52.24, NNZs: 284492, Bias: -0.925419, T: 60000, Avg. loss: 0.193975\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.31, NNZs: 287214, Bias: -0.897517, T: 70000, Avg. loss: 0.187750\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 52.36, NNZs: 289200, Bias: -0.877444, T: 80000, Avg. loss: 0.182306\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 52.41, NNZs: 290160, Bias: -0.872721, T: 90000, Avg. loss: 0.179380\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 52.46, NNZs: 291220, Bias: -0.865772, T: 100000, Avg. loss: 0.176291\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 52.49, NNZs: 292017, Bias: -0.853761, T: 110000, Avg. loss: 0.174144\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 52.53, NNZs: 292992, Bias: -0.858513, T: 120000, Avg. loss: 0.171853\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 52.56, NNZs: 293266, Bias: -0.847083, T: 130000, Avg. loss: 0.170056\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 52.58, NNZs: 293480, Bias: -0.853288, T: 140000, Avg. loss: 0.168765\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 52.60, NNZs: 293898, Bias: -0.845354, T: 150000, Avg. loss: 0.167536\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 52.62, NNZs: 294003, Bias: -0.848675, T: 160000, Avg. loss: 0.166516\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 52.64, NNZs: 294388, Bias: -0.844466, T: 170000, Avg. loss: 0.165306\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 52.67, NNZs: 294703, Bias: -0.843941, T: 180000, Avg. loss: 0.164680\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 52.68, NNZs: 294843, Bias: -0.843533, T: 190000, Avg. loss: 0.163875\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 52.70, NNZs: 295393, Bias: -0.839062, T: 200000, Avg. loss: 0.163065\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 52.71, NNZs: 295435, Bias: -0.834466, T: 210000, Avg. loss: 0.162503\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 52.72, NNZs: 295552, Bias: -0.833894, T: 220000, Avg. loss: 0.161876\n",
      "Total training time: 0.26 seconds.\n",
      "Convergence after 22 epochs took 0.26 seconds\n",
      "-- Epoch 1\n",
      "Norm: 72.84, NNZs: 225376, Bias: -0.171257, T: 10000, Avg. loss: 0.484349\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 64.06, NNZs: 263124, Bias: -0.152503, T: 20000, Avg. loss: 0.231457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 62.64, NNZs: 275970, Bias: -0.130566, T: 30000, Avg. loss: 0.190154\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 62.02, NNZs: 281269, Bias: -0.146587, T: 40000, Avg. loss: 0.167099\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61.82, NNZs: 284903, Bias: -0.135820, T: 50000, Avg. loss: 0.153315\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61.74, NNZs: 286926, Bias: -0.124363, T: 60000, Avg. loss: 0.144155\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 61.67, NNZs: 288102, Bias: -0.122360, T: 70000, Avg. loss: 0.137919\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 61.69, NNZs: 289861, Bias: -0.133709, T: 80000, Avg. loss: 0.132465\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 61.67, NNZs: 290806, Bias: -0.120632, T: 90000, Avg. loss: 0.128636\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 61.76, NNZs: 291119, Bias: -0.109844, T: 100000, Avg. loss: 0.125218\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 61.72, NNZs: 291435, Bias: -0.122061, T: 110000, Avg. loss: 0.122389\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 61.70, NNZs: 291730, Bias: -0.119906, T: 120000, Avg. loss: 0.120346\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 61.73, NNZs: 291924, Bias: -0.119633, T: 130000, Avg. loss: 0.118562\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 61.73, NNZs: 292413, Bias: -0.120616, T: 140000, Avg. loss: 0.116891\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61.70, NNZs: 292462, Bias: -0.116280, T: 150000, Avg. loss: 0.115739\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61.75, NNZs: 292603, Bias: -0.116226, T: 160000, Avg. loss: 0.114484\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61.72, NNZs: 292695, Bias: -0.121201, T: 170000, Avg. loss: 0.113546\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61.71, NNZs: 292695, Bias: -0.115754, T: 180000, Avg. loss: 0.112603\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61.74, NNZs: 292825, Bias: -0.117108, T: 190000, Avg. loss: 0.112042\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61.75, NNZs: 293007, Bias: -0.121929, T: 200000, Avg. loss: 0.111172\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 61.77, NNZs: 293042, Bias: -0.118661, T: 210000, Avg. loss: 0.110378\n",
      "Total training time: 0.25 seconds.\n",
      "Convergence after 21 epochs took 0.25 seconds\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-3, 1e-4, 1e-5),\n",
    "}\n",
    "\n",
    "sgd_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(verbose=1)),\n",
    "])\n",
    "\n",
    "gs_clf = GridSearchCV(sgd_clf, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# gs_clf.get_params().keys()\n",
    "gs_clf = gs_clf.fit(docs[2000:12000], y_train[2000:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6453\nclf__alpha: 0.0001: <class 'float'>\ntfidf__use_idf: True: <class 'bool'>\nvect__ngram_range: (1, 2): <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r: %s\" % (param_name, gs_clf.best_params_[param_name], type(gs_clf.best_params_[param_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'tuple'> True 0.0001\n"
     ]
    }
   ],
   "source": [
    "vect__ngram_range = gs_clf.best_params_['vect__ngram_range']\n",
    "tfidf__use_idf = gs_clf.best_params_['tfidf__use_idf']\n",
    "clf__alpha = gs_clf.best_params_['clf__alpha']\n",
    "print(type(vect__ngram_range), tfidf__use_idf, clf__alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "184.72967553138733\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "sgd_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=vect__ngram_range)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=tfidf__use_idf)),\n",
    "    ('clf', SGDClassifier(alpha=clf__alpha)),\n",
    "])\n",
    "\n",
    "sgd_clf.fit(docs, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6333627484706621"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "predicted = sgd_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LibLinear]432.71066641807556\n",
      "0.6765382238661704\n",
      "clf__C: 1\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC(verbose=1)),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__C': (1e-3, 1, 5),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(svm_clf, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "gs_clf = gs_clf.fit(docs[:int(len(docs)/5)], y_train[:int(len(docs)/5)])\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1 - t0)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', LinearSVC(verbose=1, C=1)),\n",
    "])\n",
    "\n",
    "svm_clf.fit(docs, y_train)\n",
    "t1 = time.time()\n",
    "print(t1 - t0)\n",
    "\n",
    "predicted = svm_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test)"
   ]
  }
 ]
}